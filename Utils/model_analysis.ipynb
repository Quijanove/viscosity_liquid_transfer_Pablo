{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "from  sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import decomposition\n",
    "\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import Matern, ConstantKernel\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Function definitions\n",
    "\n",
    "\n",
    "def analyze_scores_list_datasets(grid_search,features,target,dir_name,model_name,i=None):\n",
    "    \"\"\"\n",
    "    analyze_scores_list_datasets\n",
    "    This function performs the crossvalidation of a model for hyperparameter tuning using grid_search_cv\n",
    "    for a list of .csv files saved in a directory. It computes the mean MAE of each model across the different \n",
    "    files. finally returns a df with the values of the average and std MAE,and hyperparameter values of the model \n",
    "    with smalles MAE.\n",
    "    Args:\n",
    "    dir_name : Path of a directory containing csv files to be analyzed\n",
    "    grid_search : sklearn.model_selection.GridSearchCV object with predifined model, parameter grid and score type\n",
    "    model_name : str defning the name of the model used eg. Support Vector Regression \n",
    "    i (optional): str further narrowing the type of model used e.g. Linear in Support Vector Regression Linear\n",
    "    \"\"\"\n",
    "    score_df = pd.DataFrame() #initilize dataframe to save scores of all GridSearchCv results for all csv files\n",
    "\n",
    "    #iterate through directory\n",
    "    for file_name in os.listdir(dir_name): \n",
    "        if os.path.isfile(dir_name+file_name) == True:\n",
    "            #initilize dictionary to save scores of all GridSearchCv results for a file\n",
    "            file_dict = {}\n",
    "            #load csv as DataFrame and process for ML      \n",
    "            df = pd.read_csv(dir_name+file_name)\n",
    "            #Perform GridSearchCV with predefined parameters\n",
    "            scores = analyze_scores(data=df,grid_search=grid_search,features=features,target=target)\n",
    "            #Dump GridSearchCV scores for all the models into the dictionary\n",
    "            file_dict = {'mean_test_score'+file_name[:-4]: scores.cv_results_['mean_test_score'],\n",
    "                                    'std_test_score'+file_name[:-4]:scores.cv_results_['std_test_score']}\n",
    "            #Dump GridSearchCV scores for all the models into the DataFrame containing information of all files\n",
    "            score_df= pd.concat([score_df,pd.DataFrame(file_dict)],axis=1)\n",
    "    #Compute average for test score and std deviation of test scores for each model across all files        \n",
    "    score_df['overall_test_score'] = abs(score_df.iloc[:,::2]).mean(axis=1)\n",
    "    score_df['overall_std_test_score'] = score_df.iloc[:,1::2].mean(axis=1)\n",
    "    #Select model with minimum average score for all files and dump into a DataFrame that will be returned \n",
    "    min_index = score_df['overall_test_score'].idxmin()\n",
    "    df_score_out = score_df.loc[min_index,['overall_test_score','overall_std_test_score']]\n",
    "    df_score_out['params'] =grid_search.cv_results_['params'][min_index]\n",
    "    if i == None:\n",
    "        df_score_out.name = model_name\n",
    "    else:\n",
    "        df_score_out.name = model_name+'_'+ str(i) \n",
    "    return df_score_out\n",
    "\n",
    "def analyze_scores(grid_search,data,features,target):\n",
    "    \"\"\"\n",
    "    analyze_predictions_list_datasets\n",
    "    This function performs the crossvalidation of a model for hyperparameter tuning using grid_search_cv for a \n",
    "    DataFrame, returning a GridSearchCV object.\n",
    "    grid_search : sklearn.model_selection.GridSearchCV object with predifined model, parameter grid and score type\n",
    "    data : dataFrame containing features and target valeus to be fitted and predicted\n",
    "    features: list of column names to be used as  X input\n",
    "    target: list containing a column name used as Y input \n",
    "    \"\"\"\n",
    "    #scale features \n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = data.copy()\n",
    "    df_scaled[features] = scaler.fit_transform(df_scaled[features])\n",
    "    X = df_scaled[features]\n",
    "    y = df_scaled[target]\n",
    "\n",
    "    #split train/test sets and train model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "    #Return grid_search object with fitted data \n",
    "    return grid_search.fit(X_train,y_train)   \n",
    "\n",
    "\n",
    "def analyze_predictions_list_datasets(model, features,target,dir_name,model_name,i=None):\n",
    "    \"\"\"\n",
    "    analyze_predictions_list_datasets\n",
    "    This function is used to train and test a model with predefined hyperparameters for each\n",
    "    csv file in a directory. It saves a csv for each file containing the experimental and predicted \n",
    "    values and also a csv file with the aggregated experimental and predicted values for all files    \n",
    "    model: sklearn predicotr object with specified hyperparameters\n",
    "    features: list of column names to be used as  X input\n",
    "    target: list containing a column name used as Y input \n",
    "    dir_name : Path of a directory containing csv files to be analyzed\n",
    "    model_name : str defning the name of the model used eg. Support Vector Regression \n",
    "    i (optional): str further narrowing the type of model used e.g. Linear in Support Vector Regression Linear\n",
    "    \"\"\"\n",
    "    #Initialize a dataframe to save the aggregated predicted and experimental values for all files\n",
    "    all_predictions_df = pd.DataFrame(columns=['experimental','prediction'])\n",
    "    \n",
    "    #iterate through the csv files from the directory provided as an arg\n",
    "    for file_name in os.listdir(dir_name):\n",
    "        if os.path.isfile(dir_name+file_name) == True:\n",
    "            #create df from csv file      \n",
    "            df = pd.read_csv(dir_name+file_name)\n",
    "\n",
    "            #Fit and test data \n",
    "            prediction_df = analyze_predictions(model=model, data=df,features=features,target=target)\n",
    "            if i != None:\n",
    "                prediction_df.to_csv(file_name[:-4]+'_'+model_name+'_'+i+'.csv',index=False)\n",
    "            else:\n",
    "                prediction_df.to_csv(file_name[:-4]+'_'+model_name+'.csv',index=False)\n",
    "            #Append prediction and experimental value for this file into an aggregated dataframe\n",
    "            all_predictions_df = pd.concat([all_predictions_df,prediction_df], ignore_index= True)\n",
    "    #Save aggregated dataframe\n",
    "    if i != None:\n",
    "        all_predictions_df.to_csv(model_name+'_'+i+'.csv',index=False)\n",
    "    else:\n",
    "        all_predictions_df.to_csv(model_name+'.csv',index=False)\n",
    "    return all_predictions_df\n",
    "\n",
    "\n",
    "\n",
    "def analyze_predictions(model, data,features,target):\n",
    "    \"\"\"\n",
    "    analyze_predictions_list_datasets\n",
    "    This function is used to train and test a model with predefined hyperparameters for a givem DataFrame. \n",
    "    It perfomrs a train test split and returns a DataFrame containign the predicted and real values.\n",
    "    model: sklearn predicotr object with specified hyperparameters\n",
    "    data : dataFrame containing features and target valeus to be fitted and predicted\n",
    "    features: list of column names to be used as  X input\n",
    "    target: list containing a column name used as Y input \n",
    "    \"\"\"\n",
    "    #scale features \n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = data.copy()\n",
    "    df_scaled[features] = scaler.fit_transform(df_scaled[features])\n",
    "    X = df_scaled[features]\n",
    "    y = df_scaled[target]\n",
    "\n",
    "    #split train/test sets and train model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)     \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #use model to generate prediction and save prediction and experimental value for this file\n",
    "    prediction  = model.predict(X_test)\n",
    "    return pd.DataFrame({'experimental':y_test,'prediction':prediction})    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Import csv files that will be analyzed and plot relationships between error and liquid handling parameters\n",
    "dir_name = r'C:/Users/quijanovelascop/OneDrive - A STAR/Documents/GitHub/viscosity_liquid_transfer_Pablo/Std_calibrations'\n",
    "features = ['aspiration_rate', 'dispense_rate', 'blow_out_rate','delay_aspirate', 'delay_dispense','delay_blow_out']  \n",
    "target='%error'\n",
    "\n",
    "for file_name in os.listdir(dir_name):\n",
    "    if os.path.isfile(dir_name+'/'+file_name)==True:    \n",
    "        model_dict = {}\n",
    "        df = pd.read_csv(dir_name+'/'+file_name)\n",
    "        plot = sns.pairplot(data=df, x_vars=features, y_vars = target, hue = 'volume', palette = 'muted')\n",
    "        plot.fig.subplots_adjust(top=0.9)\n",
    "        plot.fig.suptitle(file_name[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LeaveOneOut' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\QUIJAN~1\\AppData\\Local\\Temp/ipykernel_25848/1503579763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel_list\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gpr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'poly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SVR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SGD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'KNR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'DTR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'KR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PLSR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RFR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mloo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeaveOneOut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LeaveOneOut' is not defined"
     ]
    }
   ],
   "source": [
    "# Following code returns a csv containing the pameters with the smallest MAE that predict error given\n",
    "# an input of liquid handling parameters for various regression models. \n",
    "# The parameters are found using grid search and leave one out  cross validation (looCV). For each model \n",
    "# I first obtain the MAE for each set of parameters inputed by GridSearchCV, this calculation is done \n",
    "# for each of the viscosisty standards. Then the average MAE across the different viscosity stnadards\n",
    "# is computed for each set of parameters. Finally for each model I record the set of paramters with he\n",
    "# smalles MAE into a panda dataframe, which is returned at the end for the code. \n",
    "\n",
    "dir_name = r'C:/Users/quijanovelascop/OneDrive - A STAR/Documents/GitHub/viscosity_liquid_transfer_Pablo/Std_calibrations/'\n",
    "\n",
    "\n",
    "features = ['aspiration_rate', 'dispense_rate', 'delay_aspirate', 'delay_dispense', 'blow_out_rate', 'delay_blow_out']  \n",
    "target='%error'\n",
    "\n",
    "model_list =['lin','gpr','poly', 'SVR', 'SGD','KNR','DTR','KR','PLSR','RFR']\n",
    "loo = LeaveOneOut()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_out= pd.DataFrame()\n",
    "\n",
    "for model_name in model_list:\n",
    "    if model_name == 'lin':\n",
    "        model = linear_model.LinearRegression()\n",
    "        grid ={}\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "    elif model_name =='gpr':\n",
    "        matern_tunable = ConstantKernel(1.0, (1e-5, 1e6)) * Matern(\n",
    "                        length_scale=1.0, length_scale_bounds=(1e-5, 1e6), nu=2.5)\n",
    "\n",
    "        model = GaussianProcessRegressor(kernel=matern_tunable, normalize_y=True)\n",
    "        alpha= np.arange(0.1,1.1,0.1)\n",
    "        n_restarts_optimizer= range(0,10)\n",
    "        grid = dict(alpha=alpha,n_restarts_optimizer=n_restarts_optimizer)\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "\n",
    "  \n",
    "    elif model_name == 'poly':\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                ('linear', linear_model.LinearRegression(fit_intercept=False))])          \n",
    "        grid ={}\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "    elif model_name == 'SVR':\n",
    "        for i in ['linear','rbf','sigmoid','poly']:\n",
    "            if i == 'linear':\n",
    "                model =  SVR(kernel=i)\n",
    "                C = np.arange(1,110,10)\n",
    "                epsilon = np.arange(0.1,1.1,0.1)\n",
    "                grid = dict(C=C,epsilon=epsilon)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "            \n",
    "            elif i == 'rbf':\n",
    "                model =  SVR(kernel=i)\n",
    "                C = np.arange(1,110,10)\n",
    "                epsilon = np.arange(0.1,1.1,0.1)\n",
    "                gamma = ['scale','auto']\n",
    "                grid = dict(C=C,epsilon=epsilon, gamma=gamma)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "            \n",
    "            \n",
    "            elif i == 'poly':\n",
    "                model =  SVR(kernel=i)\n",
    "                C = np.arange(1,110,10)\n",
    "                epsilon = np.arange(0.1,1.1,0.1)\n",
    "                gamma = ['scale','auto']\n",
    "                degree = range(1,4,1)\n",
    "                coef0 = (0,11,1)\n",
    "                grid = dict(C=C,epsilon=epsilon, gamma=gamma, degree= degree, coef0=coef0)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "\n",
    "            else:\n",
    "                model =  SVR(kernel=i)\n",
    "                C = np.arange(1,110,10)\n",
    "                epsilon = np.arange(0.1,1.1,0.1)\n",
    "                gamma = ['scale','auto']\n",
    "                coef0 = (0,11,1)\n",
    "                grid = dict(C=C,epsilon=epsilon, gamma=gamma,coef0=coef0)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "\n",
    "\n",
    "    elif model_name == 'SGD':\n",
    "        for i in ['l2-l1','elasticnet']:\n",
    "            if i == 'l2-l1':\n",
    "                model = linear_model.SGDRegressor(random_state=42)\n",
    "                penalty = ['l2','l1']\n",
    "                alpha = np.arange(0.0001,0.0011,0.0001)\n",
    "                learning_rate= ['constant','optimal','invscaling','adaptive']\n",
    "                power_t = np.arange(0.25,2.5,0.25)\n",
    "                grid = dict(penalty=penalty,alpha=alpha, \n",
    "                            learning_rate=learning_rate, power_t =power_t)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "            \n",
    "            if i == 'elasticnet':\n",
    "                model = linear_model.SGDRegressor(random_state=42, penalty=i)\n",
    "                alpha = np.arange(0.0001,0.0011,0.0001)\n",
    "                l1_ratio = np.arange(0,1.1,0.1)\n",
    "                learning_rate= ['constant','optimal','invscaling','adaptive']\n",
    "                power_t = np.arange(0.25,2.5,0.25)\n",
    "                grid = dict(alpha=alpha, l1_ratio= l1_ratio,\n",
    "                            learning_rate=learning_rate, power_t =power_t)                \n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "\n",
    "    elif model_name == 'KNR':\n",
    "        model =  KNeighborsRegressor()\n",
    "        n_neighbors = range(1,11,1)\n",
    "        weights= ['uniform','distance']\n",
    "        algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        leaf_size = range(1,110,10)\n",
    "        p = range(1,11,1)\n",
    "        grid = dict(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm,\n",
    "                    leaf_size=leaf_size, p=p)\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    elif model_name == 'DTR':\n",
    "        model =  DecisionTreeRegressor(random_state=42)\n",
    "        criterion = ['squared_error','friedman_mse','absolute_error','poisson']\n",
    "        splitter = ['best','random']\n",
    "        grid = dict(criterion=criterion, splitter = splitter)\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "\n",
    "    elif model_name == 'KR':\n",
    "        model =  KernelRidge()\n",
    "        alpha = np.arange(0.1,11,1)\n",
    "        for i in ['most','polynomial', 'sigmoid']:\n",
    "            if i == 'most':\n",
    "                kernel = ['additive_chi2', 'chi2', 'linear', 'poly',  'rbf', 'laplacian','cosine']\n",
    "                grid = dict (alpha=alpha, kernel=kernel)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "        \n",
    "            elif i ==  'polynomial':\n",
    "                kernel =['polynomial']\n",
    "                degree = range(1,4,1)\n",
    "                coef0 = (0,11,1)\n",
    "                grid = dict (alpha=alpha, kernel=kernel, degree=degree,coef0=coef0)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "\n",
    "            else:\n",
    "                kernel = ['sigmoid']\n",
    "                coef0 = (0,11,1)\n",
    "                grid = dict (alpha=alpha, kernel=kernel, degree=degree,coef0=coef0)\n",
    "                search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "                df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name,i=i)],axis=1)\n",
    "\n",
    "    \n",
    "    elif model_name == 'PLSR':\n",
    "        model =  PLSRegression()\n",
    "        n_components = range(1,32,10)\n",
    "        grid = dict(n_components=n_components)\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "    elif model_name == 'RFR':\n",
    "        model =  RandomForestRegressor(random_state=42)\n",
    "        criterion = ['squared_error','friedman_mse','absolute_error','poisson']\n",
    "        grid = dict(criterion=criterion)\n",
    "        search = GridSearchCV(model,grid,scoring= 'neg_mean_absolute_error', cv = loo)\n",
    "        df_out = pd.concat([df_out,analyze_scores_list_datasets(search,features,target,dir_name,model_name)],axis=1)\n",
    "\n",
    "df_out.to_csv('model_parameters_train.csv', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code computes the predictions of error given a set of liquid handling  parameters using each\n",
    "# a set of models that are implemented with teh  optimized hyperparameters obtained using the code above.\n",
    "\n",
    "dir_name = r'C:/Users/quijanovelascop/OneDrive - A STAR/Documents/GitHub/viscosity_liquid_transfer_Pablo/Std_calibrations/'\n",
    "\n",
    "\n",
    "features = ['aspiration_rate', 'dispense_rate', 'delay_aspirate', 'delay_dispense']#, 'blow_out_rate', 'delay_blow_out']  \n",
    "target='%error'\n",
    "\n",
    "model_list =['lin','gpr','poly', 'SVR', 'SGD','KNR','DTR','KR','PLSR','RFR']\n",
    "loo = LeaveOneOut()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "all_predictions_dict = {}\n",
    "    \n",
    "for model_name in model_list:\n",
    "    if model_name == 'lin':\n",
    "        model = linear_model.LinearRegression()\n",
    "        all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "    elif model_name =='gpr':\n",
    "        matern_tunable = ConstantKernel(1.0, (1e-5, 1e6)) * Matern(\n",
    "                    length_scale=1.0, length_scale_bounds=(1e-5, 1e6), nu=2.5)\n",
    "\n",
    "        model = GaussianProcessRegressor(kernel=matern_tunable, \n",
    "                                        n_restarts_optimizer=1, \n",
    "                                        alpha=0.4, \n",
    "                                        normalize_y=True)\n",
    "        all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "    \n",
    "    elif model_name == 'poly':\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                ('linear', linear_model.LinearRegression(fit_intercept=False))])          \n",
    "        all_predictions_dict[model_name] = analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "\n",
    "    elif model_name == 'SVR':\n",
    "        for i in ['linear','rbf','sigmoid','poly']:\n",
    "            if i == 'linear':\n",
    "                model =  SVR(kernel=i,C=21,epsilon=0.4)\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "            elif i == 'rbf':\n",
    "                model =  SVR(kernel=i, C=21, epsilon=0.4, gamma= 'auto')\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "            elif i == 'poly':\n",
    "                model =  SVR(kernel=i, C = 11, coef0 = 11, degree = 1, epsilon = 0.2, gamma = 'scale')\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "            else:\n",
    "                model =  SVR(kernel=i, C=11, coef0= 0, epsilon = 0.8,gamma= 'auto')\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "\n",
    "    elif model_name == 'SGD':\n",
    "        for i in ['l2-l1','elasticnet']:\n",
    "            if i == 'l2-l1':\n",
    "                model = linear_model.SGDRegressor(random_state=42, alpha=0.001,learning_rate='invscaling', penalty= 'l1', power_t = 0.25)\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "            if i == 'elasticnet':\n",
    "                model = linear_model.SGDRegressor(random_state=42, penalty=i,alpha=0.0009,learning_rate='invscaling', power_t = 0.25, l1_ratio =0.6)\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "\n",
    "    elif model_name == 'KNR':\n",
    "        model =  KNeighborsRegressor(algorithm= 'brute',leaf_size=1, n_neighbors=5,p=1,weights='uniform')\n",
    "        all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "    elif model_name == 'DTR':\n",
    "        model =  DecisionTreeRegressor(random_state=42,criterion='poisson', splitter='best')\n",
    "        all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "    elif model_name == 'KR':\n",
    "        for i in ['most','polynomial', 'sigmoid']:\n",
    "            if i == 'most':\n",
    "                model =  KernelRidge(kernel='poly',alpha=4.1)\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "                   \n",
    "            elif i ==  'polynomial':\n",
    "                model =  KernelRidge(alpha=4.1, coef0=11,degree=2,kernel='polynomial')\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "            else:\n",
    "                model =  KernelRidge(alpha=5.1, coef0=1, degree=1, kernel='sigmoid')\n",
    "                all_predictions_dict[model_name+'_'+i] = analyze_predictions_list_datasets(model, dir_name,model_name,i=i)\n",
    "    \n",
    "    # elif model_name == 'PLSR':\n",
    "    #     model =  PLSRegression(n_components = 1)\n",
    "    #     all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)\n",
    "\n",
    "    elif model_name == 'RFR':\n",
    "        model =  RandomForestRegressor(random_state=42,criterion='friedman_mse')\n",
    "        all_predictions_dict[model_name]=analyze_predictions_list_datasets(model, dir_name,model_name,i=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
