{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sartorious Experiments Data Cleaning Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Importing packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Importing files\n",
    "std = '505'\n",
    "folder = (r\"C:\\Users\\admin\\Documents\\GitHub\\viscosity_liquid_transfer_Pablo\\Sartorious_experiments\\Code\")\n",
    "\n",
    "df_raw = pd.read_csv(folder+r'/Viscosity_std_'+std+'.csv')\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Write time for 1000ul code and use that to filter and split code into smaller dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time for 1000ul\n",
    "df_raw['time_for_1000'] = 1000/df_raw[\"aspiration_rate\"] + 1000/df_raw[\"dispense_rate\"] + df_raw[\"delay_aspirate\"] + df_raw[\"delay_dispense\"] + df_raw[\"delay_blow_out\"]\n",
    "\n",
    "# Getting unique values of time in a numpy array\n",
    "TM = df_raw['time_for_1000'].unique()\n",
    "\n",
    "# Splitting the dataset into smaller datasets, each with a unique time for 1000ul value\n",
    "num = 1\n",
    "num_list = []\n",
    "for item in TM:\n",
    "    locals()[f\"df_iter{num}\"] = df_raw[df_raw['time_for_1000'] == item]\n",
    "    num_list.append(num)\n",
    "    num += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress checking code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of datasets to clean:\n",
    "total = len(TM)\n",
    "total\n",
    "\n",
    "# Number of datasets past step 2 (change the number):\n",
    "s2 = 0\n",
    "\n",
    "# Number of datasets past step 3 (change the number):\n",
    "s3 = 0\n",
    "\n",
    "print(f\"You have {total} datasets in total, you've sorted through {s2} datasets, and filtered {s3} datasets. Jiayous!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: a. Check through these dataframes to ensure no different parameters within a subsetted dataframe\n",
    "    b. If there is (different parameters within a small dataframe) make a new dataframe\n",
    "    c. Make the iteration column and assign iterations to all small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the dataset \n",
    "iteration = 1\n",
    "locals()[f\"df_iter{iteration}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making iteration column\n",
    "locals()[f\"df_iter{iteration}\"][\"iteration\"] = iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Delete duplicated data (and those with anomaly comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "col_to_drop = \n",
    "locals()[f\"df_iter{iteration}\"] = locals()[f\"df_iter{iteration}\"].drop(col_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate step: After finishing steps 3 and 4, go back to progress checking code and update s2 and s3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Append dataframe back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in num_list:\n",
    "    pd.concat([df_mod, locals()[f\"df_iter{num}\"]])\n",
    "\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
