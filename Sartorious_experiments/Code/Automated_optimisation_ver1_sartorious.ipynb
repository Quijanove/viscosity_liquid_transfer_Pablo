{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated_optimization_ver1_Sartorious (with Botorch ML suggestion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "###########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# utilities\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from torch.optim import SGD\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTorch Liquid Transfer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BO_LiqTransfer:\n",
    "\n",
    "    def __init__(self, liquid_name):\n",
    "        self.liquid_name = liquid_name\n",
    "        self._data = None\n",
    "        self.features = ['aspiration_rate','dispense_rate']\n",
    "        self.objectives = ['%error','time_asp_1000']\n",
    "        self.bmax = 1.25\n",
    "        self.bmin = 0.1\n",
    "        self._latest_suggestion = None\n",
    "        self._latest_volume = None\n",
    "        self._latest_acq_value = None\n",
    "        self.mean_volumes = [300,500,1000]\n",
    "    \n",
    "   \n",
    "    def set_data(self,df):\n",
    "        df['time_asp_1000'] = 1000/df['aspiration_rate'] + 1000/df['dispense_rate'] + df['delay_aspirate'] + df['delay_dispense']\n",
    "        if 'acq_value' not in df.columns:\n",
    "            df['acq_value'] = None\n",
    "\n",
    "        if df.loc[:,self.features].duplicated().sum()==0:\n",
    "            df_mean = df\n",
    "        else:\n",
    "            df_duplicates = df.where(df.duplicated(self.features,keep=False)==True).dropna(how='all')\n",
    "            df_incomplete = df.where(df.duplicated(self.features,keep=False)==False).dropna(how='all')\n",
    "            df_mean = pd.DataFrame(columns= df.columns)\n",
    "            for index,values in df_duplicates.drop_duplicates(self.features).iterrows():\n",
    "                if len(df_duplicates.loc[index:index+2]) == len(self.mean_volumes):\n",
    "                    mean_error =df_duplicates.loc[index:index+2,'%error'].abs().mean()\n",
    "                    df_duplicates.loc[index,'%error'] = -mean_error\n",
    "                    df_duplicates.loc[index, 'volume'] ='mean'+str(self.mean_volumes)\n",
    "                    df_mean = pd.concat([df_mean,df.loc[index:index+2],df_duplicates.loc[[index]]])\n",
    "                    \n",
    "                else:\n",
    "                    df_incomplete = pd.concat([df_incomplete,df_duplicates.loc[index:index+2]]).drop_duplicates()\n",
    "            df_mean = pd.concat([df_mean,df_incomplete])\n",
    "            df_mean = df_mean.reset_index(drop=True)    \n",
    "        self._data = df_mean\n",
    " \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def data_from_csv(self,file_name):\n",
    "        data = pd.read_csv(file_name)\n",
    "        self.set_data(data)\n",
    "\n",
    "\n",
    "\n",
    "    def update_data(self,df):\n",
    "        self._latest_volume = df['volume'].iloc[-1]\n",
    "        updated_data = pd.concat([self._data,df],ignore_index=True)\n",
    "        self.set_data(updated_data)\n",
    "        return self._data\n",
    "                                \n",
    "\n",
    "    def xy_split(self):\n",
    "        df_train = self._data.where(self._data['volume']=='mean'+str(self.mean_volumes)).dropna(how='all')\n",
    "        x_train = df_train[self.features]\n",
    "        y_train = df_train[self.objectives]\n",
    "        return x_train,y_train\n",
    "\n",
    "    def set_bounds(self, x_train):\n",
    "        return torch.vstack([x_train[0]*self.bmin, x_train[0]*self.bmax])\n",
    "\n",
    "\n",
    "\n",
    "    def fit_surrogate(self):\n",
    "        x_train, y_train = self.xy_split()\n",
    "        x_train = torch.tensor(x_train.to_numpy(dtype=float), **tkwargs)\n",
    "        y_train = torch.tensor(y_train.to_numpy(dtype=float), **tkwargs)\n",
    "        y_train[:,0] = -torch.absolute(y_train[:,0])\n",
    "        y_train[:,1] = -torch.absolute(y_train[:,1])\n",
    "\n",
    "        problem_bounds = self.set_bounds(x_train)\n",
    "        time_upper = 1000/problem_bounds[0][0] +1000/problem_bounds[0][1] + 10\n",
    "        error_upper = y_train[:,0].abs().min()*1.25\n",
    "        ref_point = torch.tensor([-error_upper,-time_upper], **tkwargs)\n",
    "\n",
    "        train_x_gp = normalize(x_train, problem_bounds)\n",
    "        models = []\n",
    "        for i in range(y_train.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x_gp, y_train[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model1 = ModelListGP(*models)\n",
    "        mll1 = SumMarginalLogLikelihood(model1.likelihood, model1)\n",
    "\n",
    "        fit_gpytorch_model(mll1)\n",
    "    \n",
    "        return model1, ref_point, train_x_gp, problem_bounds\n",
    "    \n",
    "    def optimized_suggestions(self, random_state= 42):\n",
    "        if random_state != None:\n",
    "            torch.manual_seed(random_state) \n",
    "        standard_bounds = torch.zeros(2, len(self.features), **tkwargs)\n",
    "        standard_bounds[1] = 1\n",
    "        model1, ref_point, train_x_gp, problem_bounds = self.fit_surrogate()\n",
    "        acq_func1 = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model1,\n",
    "        ref_point=ref_point, # for computing HV, must flip for BoTorch\n",
    "        X_baseline=train_x_gp, # feed total list of train_x for this current iteration\n",
    "        sampler=SobolQMCNormalSampler(sample_shape=512),  # determines how candidates are randomly proposed before selection\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=np.arange(len(self.objectives)).tolist()), # optimize first n_obj col \n",
    "        prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        sobol1 = draw_sobol_samples(bounds=standard_bounds,n=512, q=1).squeeze(1)\n",
    "        sobol2 = draw_sobol_samples(bounds=standard_bounds,n=512, q=1).squeeze(1)\n",
    "        sobol_all = torch.vstack([sobol1, sobol2])\n",
    "            \n",
    "        acq_value_list = []\n",
    "        for i in range(0, sobol_all.shape[0]):\n",
    "            with torch.no_grad():\n",
    "                acq_value = acq_func1(sobol_all[i].unsqueeze(dim=0))\n",
    "                acq_value_list.append(acq_value.item())\n",
    "                \n",
    "        # filter the best 12 QMC candidates first\n",
    "        sorted_x = sobol_all.cpu().numpy()[np.argsort((acq_value_list))]\n",
    "        qnehvi_x = torch.tensor(sorted_x[-12:], **tkwargs)  \n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(qnehvi_x, bounds=problem_bounds)\n",
    "        new_x = pd.DataFrame(new_x.numpy(),columns=['aspiration_rate','dispense_rate'])\n",
    "        new_x['acq_value'] = sorted(acq_value_list, reverse=True)[:12]\n",
    "        self._latest_suggestion = new_x[['aspiration_rate','dispense_rate']].iloc[0]\n",
    "        self._latest_acq_value = new_x['acq_value'].iloc[0]\n",
    "        return new_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\admin\\Documents\\GitHub\\viscosity_liquid_transfer_Pablo\\Sartorious_experiments\\Code\\Automated_oprimization_testing_Sartorious.ipynb\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robot initialization and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import robot related packages and run setup\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "REPOS = 'GitHub'\n",
    "ROOT = str(Path().absolute()).split(REPOS)[0]\n",
    "sys.path.append(f'{ROOT}{REPOS}')\n",
    "\n",
    "from polylectric.configs.SynthesisB1 import SETUP, LAYOUT_FILE\n",
    "\n",
    "from controllably import load_deck      # optional\n",
    "load_deck(SETUP.setup, LAYOUT_FILE)     # optional\n",
    "\n",
    "platform = SETUP\n",
    "platform.mover.verbose = False #askpablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of variables for platform objects\n",
    "pipette= platform.setup\n",
    "deck = platform.setup.deck\n",
    "balance = platform.balance\n",
    "balance_deck = deck.slots['1']\n",
    "source = deck.slots['2']\n",
    "tip_rack = deck.slots['3']\n",
    "bin = deck.slots['4']\n",
    "pipette.mover.setSpeed(50)\n",
    "print(balance_deck)\n",
    "print(source)\n",
    "print(tip_rack)\n",
    "print(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if balance is connected\n",
    "balance.zero() #to tare\n",
    "balance.toggleRecord(True) # turn on and record weight\n",
    "time.sleep(5) # do previous action for 5s\n",
    "print(balance.buffer_df.iloc[-1]) #iloc can take -1, loc needs to be 839 loc[839,[\"Time\",\"Value\",\"Factor\",\"Baseline\",\"Mass\"]]. -1 is last line. to find number of last line, print(balance.buffer_df)\n",
    "balance.toggleRecord(False) #turn off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish initial height of liquid on the source vial\n",
    "pipette_name = 'rLine1000'\n",
    "initial_liquid_level = 11.5 # in mm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing files + getting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to experiment\n",
    "std = \"204\"\n",
    "liquid_name = 'Viscosity_std_' + std \n",
    "density = 0.8639\n",
    "# Import initialisation file (Do not change)\n",
    "REPO = 'viscosity_liquid_transfer_Pablo'\n",
    "folder = os.getcwd().split(REPO)[0]+REPO+r'\\Sartorious_experiments\\Initialisation_Data' #folder that data is saved to\n",
    "liq = BO_LiqTransfer(liquid_name)\n",
    "liq.data_from_csv(folder+r'/'+'Initialisation_'+std+'.csv')\n",
    "liq._data\n",
    "\n",
    "#REPOS = 'GitHub'\n",
    "#ROOT = str(Path().absolute()).split(REPOS)[0] # this => sys.path = os.getcwd().split(REPO)[0]+REPO #askpablo\n",
    "#sys.path.append(f'{ROOT}{REPOS}') # diff between sys and os? #askpablo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if new tip is required\n",
    "pipette.mover.setSpeed(50)\n",
    "pipette.mover.setHandedness(False)\n",
    "\n",
    "if pipette.liquid.isTipOn()== False:\n",
    "    pipette.attachTip()\n",
    "\n",
    "#setup for loops\n",
    "#TO BE CHANGED\n",
    "iterations = 2\n",
    "volumes_list = [1000, 500, 300]\n",
    "\n",
    "#NOT TO BE CHANGED\n",
    "liquid_level = initial_liquid_level\n",
    "counter = 1\n",
    "\n",
    "#while loop\n",
    "while counter <= iterations:\n",
    "    #getting botorch suggestions + implementing it in liquids_dict\n",
    "    liq.optimized_suggestions()\n",
    "    liquids_dict = {\n",
    "    liquid_name :{\n",
    "            \"rLine1000\": {\n",
    "                \"aspiration_rate\": liq._latest_suggestion['aspiration_rate'], \n",
    "                \"dispense_rate\": liq._latest_suggestion['dispense_rate'], \n",
    "                \"blow_out\" : False, \n",
    "                \"delay_aspirate\" : 10, \n",
    "                \"delay_dispense\" : 10, \n",
    "                \"delay_blow_out\" : 0, \n",
    "                },\n",
    "        }\n",
    "    }\n",
    "    #for loop\n",
    "    for item in volumes_list:\n",
    "        volume = item\n",
    "        #liquid transfer\n",
    "        #transfer start\n",
    "        start = time.time() \n",
    "\n",
    "        #aspirate step\n",
    "        pipette.mover.safeMoveTo(source.wells['A1'].from_bottom((0,0,liquid_level-5))) \n",
    "        pipette.liquid.aspirate(volume, speed=liquids_dict[liquid_name][pipette_name]['aspiration_rate'])\n",
    "        time.sleep(liquids_dict[liquid_name][pipette_name]['delay_aspirate'])\n",
    "\n",
    "        pipette.touchTip(source.wells['A1']) \n",
    "\n",
    "        #dispense step\n",
    "        pipette.mover.safeMoveTo(balance_deck.wells['A1'].from_top((0,0,-5))) \n",
    "        balance.tare() \n",
    "        balance.clearCache() \n",
    "        balance.toggleRecord(True) \n",
    "        time.sleep(5)\n",
    "        pipette.liquid.dispense(volume, speed=liquids_dict[liquid_name][pipette_name]['dispense_rate'])\n",
    "        time.sleep(liquids_dict[liquid_name][pipette_name]['delay_dispense'])\n",
    "\n",
    "        #blowout step\n",
    "        if liquids_dict[liquid_name][pipette_name]['blow_out'] == True: \n",
    "            pipette.liquid.blowout(home=False)\n",
    "            time.sleep(liquids_dict[liquid_name][pipette_name]['delay_blow_out']) \n",
    "\n",
    "        #transfer termination\n",
    "        finish = time.time() \n",
    "        time_m = finish - start\n",
    "\n",
    "        pipette.mover.safeMoveTo(source.wells['A1'].top) \n",
    "        time.sleep(5)\n",
    "        balance.toggleRecord(False) \n",
    "        if liquids_dict[liquid_name][pipette_name]['blow_out'] == True:\n",
    "            pipette.liquid.home() \n",
    "\n",
    "        #do blowout\n",
    "        pipette.liquid.blowout(home=False) \n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "        time.sleep(5)\n",
    "        pipette.liquid.blowout(home=False)\n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "        time.sleep(5)\n",
    "        pipette.liquid.blowout(home=False)\n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "\n",
    "        #record transfer values \n",
    "        #calculating mass error functions\n",
    "        m = (balance.buffer_df.iloc[-10:,-1].mean()-balance.buffer_df.iloc[:10,-1].mean())/1000 \n",
    "        error = (m-density*volume/1000)/(density/1000*volume)*100\n",
    "\n",
    "        #making new dataframe + filling it in\n",
    "        df = pd.DataFrame(columns = ['liquid', 'pipette', 'volume', 'aspiration_rate', 'dispense_rate','blow_out', 'delay_aspirate', 'delay_dispense', 'delay_blow_out', 'density', 'time', 'm', '%error', 'acq_value'])\n",
    "        df = df.astype({'liquid':str,'pipette':str,'blow_out':bool})\n",
    "        df = pd.concat([df,pd.DataFrame(liquids_dict[liquid_name][pipette_name],index=[0])],ignore_index=True)\n",
    "        df.iloc[-1,-4] = time_m\n",
    "        df.iloc[-1,2] = volume\n",
    "        df.iloc[-1, 0] = liquid_name\n",
    "        df.iloc[-1, 1] = pipette_name\n",
    "        df.iloc[-1,-5] = density\n",
    "        df.iloc[-1, -3] = m\n",
    "        df.iloc[-1,-2]= error\n",
    "        df.iloc[-1, -1] = liq._latest_acq_value\n",
    "\n",
    "        #change liquid levels\n",
    "        liquid_level = liquid_level - 1.2*m/density   \n",
    "\n",
    "        #printing checks\n",
    "        print(\"LIQUID LEVEL: \" +str(liquid_level) + \"   LIQUID CHANGE: \" +str(1.2*m/density) + \"   ITERATION: \" + str(counter) + \", \" + str(volume))     \n",
    "\n",
    "        #liquid level checks\n",
    "        if (1.2*m/density > 1.2) or (1.2*m/density < 0):\n",
    "            break\n",
    "        if (liquid_level > initial_liquid_level) or (liquid_level < 6):\n",
    "            break\n",
    "\n",
    "        #update main dataframe\n",
    "        liq.update_data(df)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "\n",
    "\n",
    "pipette.ejectTipAt(bin.wells['A1'].top)\n",
    "pipette.mover.home()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save after each standard-experiment iteration\n",
    "#save after each standard-experiment iteration\n",
    "liq._data.to_csv(liquid_name+'automated_BOTorch_exp3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.ejectTipAt(bin.wells['A1'].top)\n",
    "pipette.mover.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.mover.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.liquid.eject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.mover.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.attachTip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
