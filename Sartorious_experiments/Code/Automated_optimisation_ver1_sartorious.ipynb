{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated_optimization_ver1_Sartorious (with Botorch ML suggestion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant python packages\n",
    "#%% General Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "##########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# utilities\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from torch.optim import SGD\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTorch Liquid Transfer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BO_LiqTransfer:\n",
    "\n",
    "    def __init__(self, liquid_name):\n",
    "        self.liquid_name = liquid_name\n",
    "        self._data = None\n",
    "        self.features = ['aspiration_rate','dispense_rate']\n",
    "        self.objectives = ['%error','time_asp_1000']\n",
    "        self.bmax = 1.25\n",
    "        self.bmin = 0.1\n",
    "        self._latest_suggestion = None\n",
    "        self._latest_volume = None\n",
    "        self._latest_acq_value = None\n",
    "        self.mean_volumes = [300,500,1000]\n",
    "    \n",
    "   \n",
    "    def set_data(self,df):\n",
    "        df['time_asp_1000'] = 1000/df['aspiration_rate'] + 1000/df['dispense_rate'] + df['delay_aspirate'] + df['delay_dispense']\n",
    "        if 'acq_value' not in df.columns:\n",
    "            df['acq_value'] = None\n",
    "\n",
    "        if df.loc[:,self.features].duplicated().sum()==0:\n",
    "            df_mean = df\n",
    "        else:\n",
    "            df_duplicates = df.where(df.duplicated(self.features,keep=False)==True).dropna(how='all')\n",
    "            df_incomplete = df.where(df.duplicated(self.features,keep=False)==False).dropna(how='all')\n",
    "            df_mean = pd.DataFrame(columns= df.columns)\n",
    "            for index,values in df_duplicates.drop_duplicates(self.features).iterrows():\n",
    "                if len(df_duplicates.loc[index:index+2]) == len(self.mean_volumes):\n",
    "                    mean_error =df_duplicates.loc[index:index+2,'%error'].abs().mean()\n",
    "                    df_duplicates.loc[index,'%error'] = -mean_error\n",
    "                    df_duplicates.loc[index, 'volume'] ='mean'+str(self.mean_volumes)\n",
    "                    df_mean = pd.concat([df_mean,df.loc[index:index+2],df_duplicates.loc[[index]]])\n",
    "                    \n",
    "                else:\n",
    "                    df_incomplete = pd.concat([df_incomplete,df_duplicates.loc[index:index+2]]).drop_duplicates()\n",
    "            df_mean = pd.concat([df_mean,df_incomplete])\n",
    "            df_mean = df_mean.reset_index(drop=True)    \n",
    "        self._data = df_mean\n",
    " \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def data_from_csv(self,file_name):\n",
    "        data = pd.read_csv(file_name)\n",
    "        self.set_data(data)\n",
    "\n",
    "\n",
    "\n",
    "    def update_data(self,df):\n",
    "        self._latest_volume = df['volume'].iloc[-1]\n",
    "        updated_data = pd.concat([self._data,df],ignore_index=True)\n",
    "        self.set_data(updated_data)\n",
    "        return self._data\n",
    "                                \n",
    "\n",
    "    def xy_split(self):\n",
    "        df_train = self._data.where(self._data['volume']=='mean'+str(self.mean_volumes)).dropna(how='all')\n",
    "        x_train = df_train[self.features]\n",
    "        y_train = df_train[self.objectives]\n",
    "        return x_train,y_train\n",
    "\n",
    "    def set_bounds(self, x_train):\n",
    "        return torch.vstack([x_train[0]*self.bmin, x_train[0]*self.bmax])\n",
    "\n",
    "\n",
    "\n",
    "    def fit_surrogate(self):\n",
    "        x_train, y_train = self.xy_split()\n",
    "        x_train = torch.tensor(x_train.to_numpy(dtype=float), **tkwargs)\n",
    "        y_train = torch.tensor(y_train.to_numpy(dtype=float), **tkwargs)\n",
    "        y_train[:,0] = -torch.absolute(y_train[:,0])\n",
    "        y_train[:,1] = -torch.absolute(y_train[:,1])\n",
    "\n",
    "        problem_bounds = self.set_bounds(x_train)\n",
    "        time_upper = 1000/problem_bounds[0][0] +1000/problem_bounds[0][1] + 10\n",
    "        error_upper = y_train[:,0].abs().min()*1.25\n",
    "        ref_point = torch.tensor([-error_upper,-time_upper], **tkwargs)\n",
    "\n",
    "        train_x_gp = normalize(x_train, problem_bounds)\n",
    "        models = []\n",
    "        for i in range(y_train.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x_gp, y_train[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model1 = ModelListGP(*models)\n",
    "        mll1 = SumMarginalLogLikelihood(model1.likelihood, model1)\n",
    "\n",
    "        fit_gpytorch_model(mll1)\n",
    "    \n",
    "        return model1, ref_point, train_x_gp, problem_bounds\n",
    "    \n",
    "    def optimized_suggestions(self, random_state= 42):\n",
    "        if random_state != None:\n",
    "            torch.manual_seed(random_state) \n",
    "        standard_bounds = torch.zeros(2, len(self.features), **tkwargs)\n",
    "        standard_bounds[1] = 1\n",
    "        model1, ref_point, train_x_gp, problem_bounds = self.fit_surrogate()\n",
    "        acq_func1 = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model1,\n",
    "        ref_point=ref_point, # for computing HV, must flip for BoTorch\n",
    "        X_baseline=train_x_gp, # feed total list of train_x for this current iteration\n",
    "        sampler=SobolQMCNormalSampler(sample_shape=512),  # determines how candidates are randomly proposed before selection\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=np.arange(len(self.objectives)).tolist()), # optimize first n_obj col \n",
    "        prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        sobol1 = draw_sobol_samples(bounds=standard_bounds,n=512, q=1).squeeze(1)\n",
    "        sobol2 = draw_sobol_samples(bounds=standard_bounds,n=512, q=1).squeeze(1)\n",
    "        sobol_all = torch.vstack([sobol1, sobol2])\n",
    "            \n",
    "        acq_value_list = []\n",
    "        for i in range(0, sobol_all.shape[0]):\n",
    "            with torch.no_grad():\n",
    "                acq_value = acq_func1(sobol_all[i].unsqueeze(dim=0))\n",
    "                acq_value_list.append(acq_value.item())\n",
    "                \n",
    "        # filter the best 12 QMC candidates first\n",
    "        sorted_x = sobol_all.cpu().numpy()[np.argsort((acq_value_list))]\n",
    "        qnehvi_x = torch.tensor(sorted_x[-12:], **tkwargs)  \n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(qnehvi_x, bounds=problem_bounds)\n",
    "        new_x = pd.DataFrame(new_x.numpy(),columns=['aspiration_rate','dispense_rate'])\n",
    "        new_x['acq_value'] = sorted(acq_value_list, reverse=True)[:12]\n",
    "        self._latest_suggestion = new_x[['aspiration_rate','dispense_rate']].iloc[0]\n",
    "        self._latest_acq_value = new_x['acq_value'].iloc[0]\n",
    "        return new_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\admin\\Documents\\GitHub\\viscosity_liquid_transfer_Pablo\\Sartorious_experiments\\Code\\Automated_oprimization_testing_Sartorious.ipynb\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robot initialization and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import robot related packages and run setup\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "REPOS = 'GitHub'\n",
    "ROOT = str(Path().absolute()).split(REPOS)[0]\n",
    "sys.path.append(f'{ROOT}{REPOS}')\n",
    "\n",
    "from polylectric.configs.SynthesisB1 import SETUP, LAYOUT_FILE\n",
    "\n",
    "from controllably import load_deck      # optional\n",
    "load_deck(SETUP.setup, LAYOUT_FILE)     # optional\n",
    "\n",
    "platform = SETUP\n",
    "platform.mover.verbose = False #askpablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of variables for platform objects\n",
    "pipette= platform.setup\n",
    "deck = platform.setup.deck\n",
    "balance = platform.balance\n",
    "balance_deck = deck.slots['1']\n",
    "source = deck.slots['2']\n",
    "tip_rack = deck.slots['3']\n",
    "bin = deck.slots['4']\n",
    "pipette.mover.setSpeed(50)\n",
    "print(balance_deck)\n",
    "print(source)\n",
    "print(tip_rack)\n",
    "print(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if balance is connected\n",
    "balance.zero() #to tare\n",
    "balance.toggleRecord(True) # turn on and record weight\n",
    "time.sleep(5) # do previous action for 5s\n",
    "print(balance.buffer_df.iloc[-1]) #iloc can take -1, loc needs to be 839 loc[839,[\"Time\",\"Value\",\"Factor\",\"Baseline\",\"Mass\"]]. -1 is last line. to find number of last line, print(balance.buffer_df)\n",
    "balance.toggleRecord(False) #turn off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish initial height of liquid on the source vial\n",
    "pipette_name = 'rLine1000'\n",
    "initial_liquid_level = 11.0 # in mm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing files + getting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to experiment\n",
    "std = \"817\"\n",
    "liquid_name = 'Viscosity_std_' + std \n",
    "density = 0.8466\n",
    "# Import initialisation file (Do not change)\n",
    "REPO = 'viscosity_liquid_transfer_Pablo'\n",
    "folder = os.getcwd().split(REPO)[0]+REPO+r'\\Sartorious_experiments\\Initialisation_Data' #folder that data is saved to\n",
    "liq = BO_LiqTransfer(liquid_name)\n",
    "liq.data_from_csv(folder+r'/'+'Initialisation_'+std+'.csv')\n",
    "liq._data\n",
    "\n",
    "#REPOS = 'GitHub'\n",
    "#ROOT = str(Path().absolute()).split(REPOS)[0] # this => sys.path = os.getcwd().split(REPO)[0]+REPO #askpablo\n",
    "#sys.path.append(f'{ROOT}{REPOS}') # diff between sys and os? #askpablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.optimized_suggestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquids_dict = {\n",
    "  liquid_name :{\n",
    "        \"rLine1000\": {\n",
    "            \"aspiration_rate\": liq._latest_suggestion['aspiration_rate'], \n",
    "            \"dispense_rate\": liq._latest_suggestion['dispense_rate'], \n",
    "            \"blow_out\" : False, \n",
    "            \"delay_aspirate\" : 10, \n",
    "            \"delay_dispense\" : 10, \n",
    "            \"delay_blow_out\" : 0, \n",
    "            },\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_pipetting(iterations, volume, liquid_level, df):\n",
    "    import pandas as pd\n",
    "    counter = 1\n",
    "    pipette.mover.setHandedness(False) # to fix an arm setting\n",
    "\n",
    "    while counter <= iterations:\n",
    "        #Transfer start\n",
    "        start = time.time() # green time = package to handle time #yellow time = records the current PC time\n",
    "\n",
    "        #Aspirate step\n",
    "        pipette.mover.safeMoveTo(source.wells['A1'].from_bottom((0,0,liquid_level-5))) #source=2nd plate #from_ must have coordinates, x,y,z, liquid level -3 not as good as -5 (-5 to imemerse tip)\n",
    "        pipette.liquid.aspirate(volume, speed=liquids_dict[liquid_name][pipette_name]['aspiration_rate'])\n",
    "        time.sleep(liquids_dict[liquid_name][pipette_name]['delay_aspirate'])\n",
    "\n",
    "        pipette.touchTip(source.wells['A1']) #LRUPDOWN - happens after every aspiration and blow out\n",
    "\n",
    "        #Dispense step\n",
    "        pipette.mover.safeMoveTo(balance_deck.wells['A1'].from_top((0,0,-5))) #balance_deck= 1st plate #-5 goes abit more into the well\n",
    "\n",
    "        balance.tare() \n",
    "        balance.clearCache() #clear balance memory\n",
    "        balance.toggleRecord(True) #turn on the balance\n",
    "        time.sleep(5) #stabilise the balance for 5s\n",
    "\n",
    "\n",
    "        pipette.liquid.dispense(volume, speed=liquids_dict[liquid_name][pipette_name]['dispense_rate'])\n",
    "\n",
    "        time.sleep(liquids_dict[liquid_name][pipette_name]['delay_dispense'])\n",
    "\n",
    "        #Blowout step\n",
    "        if liquids_dict[liquid_name][pipette_name]['blow_out'] == True: #do only if blowout right after dispensing is true\n",
    "            pipette.liquid.blowout(home=False)\n",
    "            time.sleep(liquids_dict[liquid_name][pipette_name]['delay_blow_out']) #delay time after doing blowout right after dispensing\n",
    "\n",
    "        #Transfer termination\n",
    "        finish = time.time() #yellow time takes pc time, green time is the package\n",
    "        time_m = finish - start\n",
    "\n",
    "        pipette.mover.safeMoveTo(source.wells['A1'].top) #move pipette to sample retrieval position for next aspiration/blowout\n",
    "        time.sleep(5)\n",
    "        balance.toggleRecord(False) #only turns off the balance recording after pipette finished dispensing\n",
    "        if liquids_dict[liquid_name][pipette_name]['blow_out'] == True:\n",
    "            pipette.liquid.home() #pipette plunger totally not depressed :)\n",
    "\n",
    "        #Do blowout\n",
    "        pipette.liquid.blowout(home=False) #askpablo\n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "        time.sleep(5)\n",
    "        pipette.liquid.blowout(home=False)\n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "        time.sleep(5)\n",
    "        pipette.liquid.blowout(home=False)\n",
    "        time.sleep(5)\n",
    "        pipette.touchTip(source.wells['A1'])\n",
    "        pipette.liquid.home()\n",
    "\n",
    "        #Record transfer values \n",
    "        m = (balance.buffer_df.iloc[-10:,-1].mean()-balance.buffer_df.iloc[:10,-1].mean())/1000 #-1: mass column #-10: = last 10 rows #:10 = first 10 rows\n",
    "\n",
    "        #Update dataframe\n",
    "        df = pd.concat([df,pd.DataFrame(liquids_dict[liquid_name][pipette_name],index=[0])],ignore_index=True) #askpablo index[0], #ignoreindex is to avoid creating additional columns\n",
    "        error = (m-density*volume/1000)/(density/1000*volume)*100\n",
    "        df.iloc[-1,-3] = time_m #-1: last row, #-3: 3rd last\n",
    "        df.iloc[-1,2] = volume\n",
    "        df.iloc[-1, 0] = liquid_name\n",
    "        df.iloc[-1, 1] = pipette_name\n",
    "        df.iloc[-1,-4] = density\n",
    "        df.iloc[-1, -2] = m\n",
    "        df.iloc[-1,-1]= error\n",
    "\n",
    "        #Check liquid levels\n",
    "        liquid_level = liquid_level - 1.2*m/density\n",
    "        print(\"LIQUID LEVEL IS \" +str(liquid_level))\n",
    "        print(\"LIQUID CHANGE IS \" +str(1.2*m/density))\n",
    "        \n",
    "\n",
    "        #Liquid level checks\n",
    "        if (1.2*m/density > 1.2) or (1.2*m/density < 0):\n",
    "            break\n",
    "        if (liquid_level > initial_liquid_level) or (liquid_level < 6):\n",
    "            break\n",
    "\n",
    "        # Increment Tries\n",
    "        counter += 1\n",
    "\n",
    "    return df, liquid_level, 1.2*m/density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if new tip is required\n",
    "pipette.mover.setSpeed(50)\n",
    "pipette.mover.setHandedness(False)\n",
    "\n",
    "if pipette.liquid.isTipOn()== False:\n",
    "    pipette.attachTip()\n",
    "\n",
    "#setup for loops\n",
    "#TO BE CHANGED\n",
    "iterations = 10\n",
    "volumes_list = [1000, 500, 300]\n",
    "#NOT TO BE CHANGED\n",
    "liquid_level = initial_liquid_level\n",
    "counter = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save after each standard-experiment iteration\n",
    "df.to_csv(liquid_name+'_optimization_exp3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.ejectTipAt(bin.wells['A1'].top)\n",
    "pipette.mover.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.mover.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette.liquid.eject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
